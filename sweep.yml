# Configuration for the hyperparameter sweep of the NER model.

program: train.py
method: bayes
project: ner-bert
metric:
  name: eval/f1
  goal: maximize
parameters:
  learning_rate:
    values: [1e-6, 3e-6, 5e-6, 7e-6, 9e-6, 2e-5, 4e-5, 6e-5, 8e-5, 1e-4, 3e-4, 5e-4, 7e-4, 9e-4]
  per_device_train_batch_size:
    values: [4,8,16,32]
  per_device_eval_batch_size:
    values: [4,8,16,32]
  num_train_epochs:
    values: [20,30,40,50]
  weight_decay:
    values: [0, 0.2, 0.4, 0.6, 0.8, 1]
  warmup_steps:
    values: [0, 5, 10, 15] 
